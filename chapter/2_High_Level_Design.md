# 2. 高层设计

ext4文件系统将存储设备分割成一系列**块组**。为了减少因为碎片化造成的性能问题，块分配器会尽力将每个文件的块保持在同一个组内，从而减少寻道时间。一个块组的大小在超级块的`s_blocks_per_group`字段中指定，以块为单位，尽管也可以通过`8 * block_size_in_bytes`计算得到。以默认的`4KiB`块大小来说，每个组将包含`32,768`个块，长度为`128MiB`。块组的数量是设备大小除以块组大小。

**`ext4`中的所有字段都以小端序写入磁盘。但是，`jbd2`（日志）中的所有字段都以大端序写入磁盘**。

## 2.1. 块

ext4以"块"为单位分配存储空间。一个块是由`1KiB`到`64KiB`之间的扇区组成的组，并且扇区数量必须是2的整数次幂。块又被分组成更大的单位，称为块组。块大小在创建文件系统时指定，通常为`4KiB`。如果块大小大于页面大小，可能会遇到挂载问题（例如，在只有`4KiB`内存页面的i386上使用`64KiB`的块）。默认情况下，一个文件系统最多可以包含2^32个块；如果启用了'64bit'特性，那么文件系统可以拥有2^64个块。结构的位置是以结构所在的块号存储的，而不是磁盘上的绝对偏移量。

对于32位文件系统，限制如下：

| 条目 | 1KiB | 2KiB | 4KiB | 64KiB |
| ------ | ---- | ---- | ---- | ---- |
|块数| 2^32 | 2^32 | 2^32 | 2^32 |
|inode数| 2^32 | 2^32 | 2^32 | 2^32 |
| 文件系统大小 | 4TiB | 8TiB | 16TiB | 256TiB | 
| 每块组块数 | 8,192 | 16,384 | 32,768 | 524,288 |
| 每块组inode数 | 8,192 | 16,384 | 32,768 | 524,288 |
| 块组大小 | 8MiB | 32MiB | 128MiB | 32GiB 
| 每个文件的块数，扩展模式 | 2^32 | 2^32 | 2^32 | 2^32 |
| 每个文件的块数，块映射模式 | 16,843,020 | 134,480,396 | 1,074,791,436 | 4,398,314,962,956 (实际上是2^32，受字段大小限制) |
| 文件大小，扩展模式 | 4TiB | 8TiB | 16TiB | 256TiB |
| 文件大小，块映射模式 | 16GiB | 256GiB | 4TiB | 256TiB |

对于64位文件系统，限制如下：

| 条目 | 1KiB | 2KiB | 4KiB | 64KiB |
| ------- | ---- | ---- | ---- | ---- |
| 块数 | 2^64 | 2^64 | 2^64 | 2^64 |
| inode数 | 2^32 | 2^32 | 2^32 | 2^32 |
| 文件系统大小 | 16ZiB | 32ZiB | 64ZiB | 1YiB |
| 每块组块数 | 8,192 | 16,384 | 32,768 | 524,288 | 
| 每块组inode数 | 8,192 | 16,384 | 32,768 | 524,288 |
| 块组大小 | 8MiB | 32MiB | 128MiB | 32GiB |
| 每个文件的块数，扩展模式 | 2^32 | 2^32 | 2^32 | 2^32 |
| 每个文件的块数，块映射模式 | 16,843,020 | 134,480,396 | 1,074,791,436 | 4,398,314,962,956 (实际上是2^32，受字段大小限制) |
| 文件大小，扩展模式 | 4TiB | 8TiB | 16TiB | 256TiB |
| 文件大小，块映射模式 | 16GiB | 256GiB | 4TiB | 256TiB |

> 注意：不使用扩展（即使用块映射）的文件必须位于文件系统的前2^32个块内。使用扩展的文件必须位于文件系统的前2^48个块内。对于更大的文件系统会发生什么情况尚不清楚。

## 2.2. 布局

标准块组的布局大致如下（下面将分别讨论这些字段中的每一个）：

|第0组填充|ext4超级块|组描述符|保留的GDT块|数据块位图|inode位图|inode表| 数据块|
| ------ | -------- | ----- | -------- | -------- | ------ | ----- | ---- | 
|1024字节|   1个块  | 多个块 |  多个块  |  1个块  |  1个块  | 多个块 | 更多块|


对于块组0的特殊情况，前1024字节未使用，以允许安装x86引导扇区和其他特殊情况。超级块将从偏移1024字节开始，无论是哪个块（通常是0）。然而，如果由于某种原因块大小 = 1024，那么块0将被标记为使用中，超级块将放在块1中。对于所有其他块组，没有填充。

> 注：无论哪种情况，块0都会被标记为已使用。

`ext4`驱动程序主要处理块组0中的超级块和组描述符。超级块和组描述符的冗余副本会写入磁盘上的一些块组中，以防磁盘开始部分损坏，尽管并非所有块组都必须托管冗余副本（详见下段）。如果组没有冗余副本，则块组从数据块位图开始。还要注意，当文件系统刚刚格式化时，mkfs将在块组描述符之后和块位图开始之前分配"保留GDT块"空间，以允许将来扩展文件系统。默认情况下，文件系统允许比原始文件系统大小增加1024倍。

> 注：在ext4文件系统中，有多个块组（block groups）。每个块组内部的布局可能不同，主要有两种不同类型的块组：
>   1. 有冗余副本的块组：
>   + 这些特定的块组会存储超级块和组描述符的备份副本
>   + 这些块组的布局是：开头部分存放超级块备份 → 然后是组描述符表备份 → 然后才是数据块位图、inode位图等其他内容
>   + 这些备份是为了文件系统恢复而设计的
>   2. 没有冗余副本的块组：
>   + 其他大多数块组不需要存储这些备份
>   + 这些块组的布局是：直接从数据块位图开始 → 然后是inode位图等其他内容
>   + 它们没有超级块和组描述符的副本，因此结构更简单

inode表的位置由`grp.bg_inode_table_*`给出。它是一个连续的块范围，足够大以包含`sb.s_inodes_per_group * sb.s_inode_size`字节。

至于块组中项目的顺序，通常确定超级块和组描述符表（如果存在）将位于块组的开头。位图和inode表可以在任何地方，并且位图可能位于inode表之后，或者两者可能位于不同的组（flex_bg）。剩余空间用于文件数据块、间接块映射、扩展树块和扩展属性。

> 在`ext4`文件系统中引入的`flex_bg`（灵活块组）特性确实允许位图和inode表位于不同的块组中。

## 2.3. 灵活块组

从ext4开始，有一个新特性叫做灵活块组（flex_bg）。在flex_bg中，几个块组被绑定在一起作为一个逻辑块组；`flex_bg`第一个块组中的位图空间和inode表空间被扩展，以包含flex_bg中所有其他块组的位图和inode表。例如，如果`flex_bg`大小为4，那么组0将依次包含超级块、组描述符、组0-3的数据块位图、组0-3的inode位图、组0-3的inode表，组0中的剩余空间用于文件数据。这样做的效果是将块组元数据集中在一起以加快加载速度，并使大文件能够在磁盘上连续存储。超级块和组描述符的备份副本总是位于块组的开头，即使启用了flex_bg。组成flex_bg的块组数量由`2 ^ sb.s_log_groups_per_flex`给出。

> 1. flex_bg的第一个块组(组0)会包含：
> + 超级块
> + 组描述符表
> + 所有成员块组(例如0-3)的数据块位图
> + 所有成员块组(例如0-3)的inode位图
> + 所有成员块组(例如0-3)的inode表
> + 以及组0自己的文件数据(剩余空间)
>
> 2. flex_bg内的其他块组(比如组1、2、3):
> + 它们的元数据(位图和inode表)集中存放在组0中
> + 这些块组几乎全部空间都用于存放文件数据
> + 但它们仍会在开头包含超级块和组描述符的备份(如果配置了备份)

## 2.4. 元块组

在没有`META_BG`选项的情况下，出于安全考虑，所有块组描述符副本都保存在第一个块组中。考虑到默认128MiB（2^27字节）的块组大小和64字节的组描述符，ext4最多可以有2^27/64 = 2^21个块组。这将整个文件系统大小限制为2^21 * 2^27 = 2^48字节或256TiB。

解决这个问题的方法是使用元块组特性（META_BG），这已经在ext3的所有2.6版本中使用。使用META_BG特性，ext4文件系统被分成许多元块组。每个元块组是一个块组集群，其组描述符结构可以存储在单个磁盘块中。对于具有4KB块大小的ext4文件系统，单个元块组分区包括64个块组，或8GiB的磁盘空间。元块组特性将组描述符的位置从整个文件系统的拥挤的第一个块组移到每个元块组本身的第一个组中。备份位于每个元块组的第二个和最后一个组中。这将`2^21`个最大块组限制增加到`2^32`的硬限制，允许支持512PiB的文件系统。

文件系统格式的变化取代了当前超级块后跟可变长度的块组描述符集的方案。相反，超级块和单个块组描述符块被放置在元块组中的第一个、第二个和最后一个块组的开头。元块组是可以由单个块组描述符块描述的块组集合。由于块组描述符结构的大小为64字节，对于具有1KB块大小的文件系统，元块组包含16个块组，对于具有4KB块大小的文件系统，元块组包含64个块组。文件系统可以使用这种新的块组描述符布局创建，或者现有文件系统可以在线调整大小，超级块中的`s_first_meta_bg`字段将指示使用这种新布局的第一个块组。

请参阅关于块和inode位图部分中关于`BLOCK_UNINIT`的重要说明。

> 1. META_BG特性解决方案：
> + 已在ext3的所有2.6版本中使用
> + 将文件系统划分为多个"元块组"(meta block groups)
> + 每个元块组是一个块组集群，其组描述符可存储在单个磁盘块中
> + 例如：4KB块大小的文件系统中，一个元块组包含64个块组或8GiB空间
> 2. 存储结构变化：
> + 将组描述符从整个文件系统的第一个块组移动到每个元块组的第一个组
> + 备份存储在每个元块组的第二个和最后一个组中
> + 超级块和单个块组描述符块被放置在元块组中的第一个、第二个和最后一个块组的开头

## 2.5. 延迟块组初始化

ext4的一个新特性是三个**块组描述符标志**，使mkfs能够跳过初始化块组元数据的其他部分。具体来说，`INODE_UNINIT`和`BLOCK_UNINIT`标志意味着该组的inode和块位图可以被计算，因此不初始化磁盘上的位图块。这通常是空块组或只包含固定位置块组元数据的块组的情况。`INODE_ZEROED`标志意味着inode表已经初始化；mkfs将取消设置此标志，并依靠内核在后台初始化inode表。

通过不向位图和inode表写入零，mkfs时间大大减少。注意，特性标志是`RO_COMPAT_GDT_CSUM`，但`dumpe2fs`输出打印为"uninit_bg"。它们是同一件事。

## 2.6. 特殊inode

ext4为特殊功能保留一些inode，如下所示：

|inode编号|用途|
|:--------:|---|
|0|不存在；没有inode 0。|
|1|有缺陷块的列表。|
|2|根目录。|
|3|用户配额。|
|4|组配额。|
|5|引导加载程序|
|6|未删除目录。|
|7|保留的组描述符inode。（"调整大小inode"）|
|8|日志inode。|
|9|"排除"inode，用于快照(?)|
|10|复制inode，用于一些非上游功能？|
|11|传统的第一个非保留inode。通常这是lost+found目录。参见超级块中的s_first_ino。|

注意，还有一些从非保留inode编号分配的inode用于其他文件系统功能，这些功能不从标准目录层次结构引用。这些通常从超级块引用。它们是：


| 超级块字段 | 描述 |
| -------- | ---- | 
|s_lpf_ino| lost+found目录的inode编号。|
|s_prj_quota_inum|跟踪项目配额的配额文件的inode编号。|
|s_orphan_file_inum|跟踪孤立inode的文件的inode编号。|

## 2.7. 块和Inode分配策略

ext4认识到（比ext3更好）数据局部性通常是文件系统期望的质量。在旋转磁盘上，将相关块保持在彼此附近减少了访问数据块时磁头执行器和磁盘必须执行的移动量，从而加速磁盘IO。在SSD上当然没有移动部件，但局部性可以增加每个传输请求的大小，同时减少请求的总数。这种局部性也可能会将写入集中在单个擦除块上，这可能会显著加快文件重写速度。因此，尽可能减少碎片化是有用的。

ext4用来对抗碎片化的第一个工具是**多块分配器**。当首次创建文件时，块分配器会推测性地为文件分配8KiB的磁盘空间，假设该空间将很快被写入。当文件关闭时，未使用的推测性分配当然会被释放，但如果推测正确（通常是小文件的完整写入情况），那么文件数据将以单个多块扩展写出。ext4使用的第二个相关技巧是**延迟分配**。在这种方案下，当文件需要更多块来吸收文件写入时，文件系统推迟决定磁盘上的确切位置，直到所有脏缓冲区都被写出到磁盘。通过不承诺特定位置，直到绝对必要（提交超时被击中，或调用`sync()`，或内核耗尽内存），希望文件系统能够做出更好的位置决策。

ext4（和ext3）使用的第三个技巧是，它尝试将文件的数据块保持在与其inode相同的块组中。当文件系统首先必须读取文件的inode以了解文件的数据块在哪里，然后寻找到文件的数据块以开始I/O操作时，这减少了寻道惩罚。

> 注：**寻道惩罚**（Seek Penalty）指的是在磁盘存储系统中，由于磁头需要在磁盘的不同轨道之间移动（寻道）而导致的额外时间开销。

第四个技巧是，目录中的所有inode在可行的情况下都放在与目录相同的块组中。这里的工作假设是目录中的所有文件可能相关，因此尝试将它们都保持在一起是有用的。

第五个技巧是，磁盘卷被切成128MB的块组；这些迷你容器如上所述用于尝试维持数据局部性。然而，有一个故意的怪癖——当在根目录中创建目录时，inode分配器会扫描块组，并将该目录放入它能找到的负载最轻的块组中。这鼓励目录在磁盘上展开；随着顶级目录/文件blob填满一个块组，分配器简单地移动到下一个块组。据称这种方案平衡了块组上的负载，尽管作者怀疑那些不幸落在旋转驱动器末端的目录在性能方面得到了原始交易。

当然，如果所有这些机制都失败了，可以使用`e4defrag`来对文件进行碎片整理。

## 2.8. 校验和

从2012年初开始，元数据校验和被添加到所有主要的ext4和jbd2数据结构中。相关的特性标志是`metadata_csum`。期望的校验和算法在超级块中指示，尽管截至2012年10月，唯一支持的算法是crc32c。一些数据结构没有空间容纳完整的32位校验和，因此只存储低16位。启用64bit特性增加了数据结构大小，以便可以为许多数据结构存储完整的32位校验和。然而，现有的32位文件系统无法扩展以启用64位模式，至少不能在没有实验性`resize2fs`补丁的情况下这样做。

现有文件系统可以通过对底层设备运行`tune2fs -O metadata_csum`来添加校验和。如果`tune2fs`遇到缺少足够空闲空间以添加校验和的目录块，它将请求您运行`e2fsck -D`以使目录重建带有校验和。这有额外的好处，即从目录文件中删除空闲空间并重新平衡htree索引。如果您_忽略_此步骤，您的目录将不会受到校验和的保护！

下表描述了进入每种类型的校验和的数据元素。校验和函数是超级块描述的任何函数（截至2013年10月为crc32c），除非另有说明。

| 元数据 | 长度 | 成分 |
|-------|-----|-----|
| 超级块 | __le32 | 超级块中直到校验和字段的整个部分。UUID位于超级块内。|
| MMP | __le32 | UUID + 整个MMP块直到校验和字段。|
|扩展属性|__le32|UUID + 整个扩展属性块。校验和字段设置为零。|、
|目录条目|__le32|UUID + inode编号 + inode生成 + 目录块直到包含校验和字段的假条目。|
|HTREE节点|__le32|UUID + inode编号 + inode生成 + 所有有效扩展 + HTREE尾部。校验和字段设置为零。|
|扩展|__le32|UUID + inode编号 + inode生成 + 整个扩展块直到校验和字段。|
|位图|__le32或__le16|UUID + 整个位图。校验和存储在组描述符中，如果组描述符大小为32字节（即^64bit），则被截断。|
|Inode|__le32|UUID + inode编号 + inode生成 + 整个inode。校验和字段设置为零。每个inode都有自己的校验和。|
|组描述符|__le16|如果metadata_csum，则UUID + 组编号 + 整个描述符；否则如果gdt_csum，则crc16(UUID + 组编号 + 整个描述符)。在所有情况下，只存储低16位。|

## 2.9. 大分配

目前，块的默认大小为4KiB，这是大多数支持MMU的硬件上常见的页面大小。这是幸运的，因为ext4代码尚未准备好处理块大小超过页面大小的情况。然而，对于大多数都是巨大文件的文件系统，能够以多个块为单位分配磁盘块是可取的，以减少碎片化和元数据开销。bigalloc特性提供了这种能力。

bigalloc特性（EXT4_FEATURE_RO_COMPAT_BIGALLOC）改变ext4使用集群分配，使得ext4块分配位图中的每个位址2的幂次方数量的块。例如，如果文件系统主要存储4-32兆字节范围内的大文件，设置1兆字节的集群大小可能有意义。这意味着块分配位图中的每个位现在寻址256个4k块。这将2T文件系统的块分配位图总大小从64兆字节缩小到256千字节。这也意味着块组寻址32千兆字节而不是128兆字节，也减少了文件系统元数据的开销。

管理员可以在mkfs时设置块集群大小（存储在超级块的`s_log_cluster_size`字段中）；从那时起，块位图跟踪集群，而不是单个块。这意味着块组可以是几个千兆字节大小（而不仅仅是128MiB）；然而，最小分配单元变成一个集群，而不是一个块，即使对于目录也是如此。TaoBao有一个补丁集将"使用集群单位而不是块"扩展到扩展树，尽管不清楚这些补丁去了哪里——它们最终演变成"扩展树v2"，但截至2015年5月，该代码尚未登陆。

## 2.10. 内联数据

内联数据特性旨在处理文件数据非常小，以至于可以轻松放入inode内部的情况，这（理论上）减少了磁盘块消耗并减少了寻道。如果文件小于60字节，则数据存储在`inode.i_block`中内联。如果文件的其余部分可以放入扩展属性空间，则它可能作为扩展属性"system.data"在inode主体（"ibody EA"）内找到。这当然限制了可以附加到inode的扩展属性数量。如果数据大小增加超出i_block + ibody EA，将分配一个常规块并将内容移动到该块。

等待更改以压缩用于存储内联数据的扩展属性键，应该能够在256字节的inode中存储160字节的数据（截至2015年6月，当i_extra_isize为28时）。在此之前，由于inode空间使用效率低下，限制为156字节。

内联数据特性需要"system.data"的扩展属性，即使属性值为零长度。

### 2.10.1. 内联目录

i_block的前四个字节是父目录的inode编号。接下来是56字节的空间，用于目录条目数组；见`struct ext4_dir_entry`。如果inode主体中有"system.data"属性，EA值也是`struct ext4_dir_entry`的数组。注意，对于内联目录，i_block和EA空间被视为单独的dirent块；目录条目不能跨越两者。

内联目录条目不进行校验和，因为inode校验和应保护所有内联数据内容。

## 2.11. 大型扩展属性值

为了使ext4能够存储不适合inode或附加到inode的单个扩展属性块中的扩展属性值，`EA_INODE`特性允许我们将值存储在常规文件inode的数据块中。这个"EA inode"只从扩展属性名称索引链接，不得出现在目录条目中。inode的i_atime字段用于存储xattr值的校验和；i_ctime/i_version存储64位引用计数，这使得多个拥有inode之间可以共享大xattr值。为了向后兼容此特性的旧版本，i_mtime/i_generation可能存储对一个拥有inode的inode编号和i_generation的反向引用（在EA inode不被多个inode引用的情况下），以验证EA inode是正在访问的正确inode。

## 2.12. Verity文件

ext4支持fs-verity，这是一个文件系统特性，为单个只读文件提供基于Merkle树的哈希。大部分fs-verity对所有支持它的文件系统都是通用的；有关fs-verity文档，请参阅`Documentation/filesystems/fsverity.rst`。然而，verity元数据的磁盘布局是特定于文件系统的。在ext4上，verity元数据存储在文件数据本身的末尾之后，格式如下：

+ 零填充到下一个65536字节边界。这个填充实际上不需要在磁盘上分配，即它可能是一个空洞。
+ Merkle树，如`Documentation/filesystems/fsverity.rst`中所述，树级别按从根到叶的顺序存储，每个级别内的树块按其自然顺序存储。
+ 零填充到下一个文件系统块边界。
+ verity描述符，如`Documentation/filesystems/fsverity.rst`中所述，可选附加签名blob。
+ 零填充到距文件系统块边界4字节之前的下一个偏移量。
+ verity描述符的大小（以字节为单位），作为4字节小端整数。

Verity inode有`EXT4_VERITY_FL`设置，它们必须使用扩展，即必须设置`EXT4_EXTENTS_FL`，必须清除`EXT4_INLINE_DATA_FL`。它们可以设置`EXT4_ENCRYPT_FL`，在这种情况下，verity元数据以及数据本身都会被加密。
Verity文件不能在verity元数据末尾之后分配块。
Verity和DAX不兼容，尝试在文件上同时设置这两个标志将失败。